<< 데이터프레임 >>

- 데이터프레임은 2차원 배열. R의 데이터프레임에서 유래.
- 데이터프레임의 열은 각각 시리즈 개체.
- 시리즈를 열벡터라고 하면 데이터프레임은 여러개의 열벡터들이 같은 행 인덱스를 기준으로 줄지어 결합된 2차원 벡터 또는 행렬.
- 선형대수학에서 열 벡터(m x 1 행렬)는 m 원소들의 단일 열 행렬
- 행 벡터(1 x m 행렬)은 m원소들의 단일 행 행렬.
- 리스트, 딕셔너리, ndarray 등 다양한 데이터로부터 생성
- 반대로 리스트, 딕셔너리, ndarray 등으로 변환될 수 있음

=============================================================

<< 데이터프레임 정보 확인 >>

변수명.info() 
- 인덱스, 열 개수, 각 열 별 non-null 개수, 데이터 타입 정보 제공


데이터프레임.columns
- 데이터프레임의 열이름 확인 


데이터프레임.describe()
- 데이터프레임의 통계적 정보 확인
- count, mean, std, min, 25%, 50%, 75%, max 값 제공
  e.g. df2.describe()


=============================================================

<< 데이터프레임 생성 >>

기본 형태:
  변수명=pd.DataFrame(데이터가 들었는 변수명, 
                      index=['인덱스1',...,'인덱스n'],
                      columns=['열이름1',...'열이름n'])
                      ** index 는 행 이름 개별 지정
                      ** columns 는 열 이름 개별 지정
    e.g.
    import random
    import numpy as np
    import pandas as pd
    np.random.seed(0) # <== seed(숫자)를 먼저 넣어주면 생성된 랜덤 숫자가 동일한 seed 숫자가 유지되는 한, 몇번을 다시 돌려도 같은 숫자로 고정되어서 나옴
    data=np.random.randint(100,120,size=(3,3))
    print(data,type(data))
    
    df=pd.DataFrame(data,index=['d1','d2','d3'],
                    columns=['pd','sales','inv'])
    print(df)

** 데이터 랜덤하게 생성하고 싶다면:
  np.random.seed(0) 
  data=np.random.randint(시작,끝,size=(행 개수,열 개수))
  ==> seed(숫자)를 먼저 넣어주면 생성된 랜덤 숫자가 동일한 seed 숫자가 유지되는 한, 
      몇번을 다시 돌려도 같은 숫자로 고정되어서 나옴

  e.g. np.random.seed(0) 
       data=np.random.randint(100,120,size=(3,3))


<< 데이터프레임 복사 >>

변수명1=변수명2.copy()
  e.g. df1.df.copy()
       ==> df를 카피하는 것임


<< 전치 (행과 열 바꾸기) >>
데이터프레임.transpose()
  e.g. df1_t=df1.transpose()


=============================================================

<< 변수의 고유값 확인 >>

데이터프레임.열이름.unique() 
  e.g. df.horsepower.unique()
  ==> df 데이터프레임의 horsepower 변수에 들어간 고유 값을 중복 없이 리스트 받아 확인 가능

=============================================================

<< 생성된 데이터프레임에서의 수정 >>

---- [ 행/열의 값 수정 ] ----

- 행 값 수정 :
    기본 형태:
      데이터프레임.loc['행이름']=수정값

- 행 값 추가 :
  ** 행 추가 시 loc로는 가능 iloc는 불가능
    기본 형태:
      데이터프레임.loc['행이름']=추가할 값
        e.g df.loc['d4']=0
        ==> 데이터 수정 때와 같은 방식임

- 열 값 추가 :
      데이터프레임.loc[:, '열이름']=추가할 값
        e.g. df.loc[:,'profit']=10


---- [ 조건에 맞는 행 뽑을 때 ] ----

변수명=df.loc['인덱스 조건','시작 열이름':'끝 열이름']
e.g. df_ym=df.loc['2018-07','Start':'High']



---- [ 헹/열 수정 ] ----

- 열 추가 :
    데이터프레임['추가할 열이름']=list(행마다 들어갈 값)
    e.g. df1['index']=list('가나다라마')


- 열이름 수정 :
    데이터프레임.rename(columns={열1:'수정할 열이름',...열n:'수정할 열이름'}, inplace=True) 
      e.g. df.rename(columns={0:'id',1:'gender',2:'age',3:'region'}, inplace=True)
      ==> inplace=True : 이렇게 바꾼 것을 원본에 반영하겠다는 의미 

- 열, 행 이름 동시에 변경 :
    columns={'기존 열이름':'수정할 열이름',...}
    index={'기존 행이름':'수정할 행이름',...}
    데이터프레임.rename(columns=columns, index=index, inplace=True)


- 특정 열 삭제 
    데이터프레임.drop('열이름', axis=1)
    e.g. df21=df2.drop('e', axis=1)

- 특정 행 삭제
    데이터프레임.drop([삭제할 인덱스], axis=0, inplace=True)
      e.g. df.drop([0],axis=0,inplace=True)
      ==> axis=0 : 축이 행. 즉, 행 삭제


---- [ 데이터타입 수정 ] ----

- 데이터프레임의 데이터타입 일괄 수정 
    데이터프레임.astype(변경할 데이터타입)
    e.g. df4.astype(float)

- 특정 열의 데이터타입 수정
    데이터프레임['열이름']=데이터프레임['열이름'].astype(변경할 데이터타입)
    e.g. df4['B']=df4['B'].astype(float)

- datetime으로 데이터타입 변환 
    데이터프레임['열이름']=pd.to_datetime(데이터프레임['열이름'])
    e.g. df4['C']=pd.to_datetime(df4['C'])

- 테이터프레임의 각 열의 테이터타입 확인 
    print(변수명1.dtypes)
    e.g. print(df4.dtypes)

  
---- [ 인덱스 수정 ] ----

- 인덱스 열 변경 :
    데이터프레임.set_index('인덱스 열 이름')
    e.g. df2=df1.set_index('index')

- 인덱스 열 원복 :
    데이터프레임.reset_index()
    e.g. df3=df21.reset_index()

- 인덱스 열 이름 삭제 :
    데이터프레임.index.name=None
    e.g. df22.index.name=None

- 인덱스 삭제 :
    1. 슬라이싱 :
       데이터프레임.drop(데이터프레임.index[시작:끝])
       e.g. df1=df5.drop(df5.index[5:9])
    
    2. drop :
       데이터프레임.drop(['삭제할 인덱스 리스팅'], axis=0)
       e.g. f1=f5.drop(['r5','r6','r7','r8'],axis=0)


- 인덱스 추가/삭제/수정 
    변수명=['새로 보여줄 인덱스 리스팅']
    데이터프레임.reindex(변수명)
    e.g. new_index=['r0','r1','r2','r3','r4']
         df1=df5.reindex(new_index,fill_value=0)
         ==> 기존 인덱스가 몇개든 상관없이 new_index에서 지정한 개수만큼만 보여짐

- 인덱스 추가/삭제/수정 + NaN은 0처리
    데이터프레임.reindex(인덱스명,fill_value=0)
    ==> 새로 추가되는 인덱스의 행에 대한 값은 모두 0으로 처리
    e.g. new_index=['r0','r1','r2','r3','r4','r5','r6','r7','r8']
         df5=df.reindex(new_index,fill_value=0)

- 기존 인덱스에 인덱스 새로 추가하고 싶을 경우 
    ** union 사용
      1. 추가하고 싶은 인덱스를 새 변수명으로 만들어주고
      2. 새 변수명으로 기존인덱스명.union(추가할 인덱스 변수명)
      3. 데이터프레임을 union으로 합친 인덱스로 재인덱싱
      e.g. 
            # 추가하고 싶은 인덱스
            add_index=pd.date_range('2024-01-05',periods=3,freq='3D')
          
            # 기존 인덱스와 새로운 인덱스 합치기
            new_index=dates.union(add_index) # 기존 인덱스: dates. 추가할 인덱스: add_index
            
            # 데이터프레임을 새로운 인덱스로 재인덱싱, fill_value로 null값 0
            df5_4=df5_3.reindex(new_index,fill_value=0)


---- [ 인덱스 정렬 ] ----

- 인덱스 내림차순 정렬 :
    데이터프레임.sort_index(ascending=False)
    e.g. df1_s=df1.sort_index(ascending=False)

- 특정 value 기준으로 정렬 :
    데이터프레임.sort_values(by='열이름', ascending=False)
    e.g. df1_c=df1.sort_values(by='c',ascending=False)


=============================================================

<< 데이터프레임 병합 >>

---- [ 데이터프레임끼리의 병합 ] -----
- 행방향 병합 (가로로)
    pd.concat([데이터프레임1, 데이터프레임2],axis=1)
    ==> 데이터프레임1 우측으로 데이터프레임2가 붙음


- 열방향 병합 (세로로)
    pd.concat([데이터프레임1, 데이터프레임2])
    ==> 데이터프레임1 밑으로 데이터프레임2가 붙음

- 단순 더하기로 이을 수 있음:
  데이터프레임1+데이터프레임2
  e.g. df1=pd.DataFrame(np.arange(12.).reshape((3,4)),columns=list('abcd'))
       df2=pd.DataFrame(np.arange(20.).reshape((4,5)),columns=list('abcde'))
       df1+df2
       ==> 결과:        
          a	b	c	d	e
          0	0.0	2.0	4.0	6.0	NaN
          1	9.0	NaN	13.0	15.0	NaN
          2	18.0	20.0	22.0	24.0	NaN
          3	NaN	NaN	NaN	NaN	NaN
          ** 데이터프레임끼리 합쳐질 때는 행과 열의 수가 맞지 않아도 됨.
             다만, 행과 열의 수가 맞지 않은 곳의 값은 NaN이 들어가게 됨 (연산이 불간능하므로)


---- [ 시리즈 --> 데이터프레임 병합 ] ----

- 여러 시리즈를 하나로 합칠 때:
  pd.concat([시리즈1, 시리즈2, 시리즈3], axis=1)
  e.g. add=st1+st2
       sub=st1-st2
       mul=st1*st2
       div=round((st1/st2),2)
       df=pd.concat([add,sub,mul,div],axis=1)
       
- 여러 시리즈를 하나의 데이터프레임으로 만들 때:
  데이터프레임명=pd.DataFrame([시리즈1, 시리즈2,...])
  e.g. result=pd.DataFrame([add,sub,mul,div])

- 여러 시리즈를 하나의 데이터 프레임으로 합치면서 null값은 0으로 만들어준다면,
  시리즈 단에서 fill_value=0 사용해서 null -> 0으로 미리 대체해주기 
  e.g. st1 = pd.Series({'국어':np.nan,'영어':80,'수학':90})
       st2 = pd.Series({'수학':80,'국어':90})
      
       ad = st1.add(st2,fill_value=0)
       su = st1.sub(st2,fill_value=0)
       mu = st1.mul(st2,fill_value=0)
       di = st1.div(st2,fill_value=0)
      
       df = pd.DataFrame([add,sub,mul,div],
                            index=['덧셈','뺄셈','곱셈','나눗셈'])


---- [ 인덱스 수정 ] ----

- 합친 시리즈의 인덱스 이름 수정:
  변수명.columns=['인덱스 이름 리스팅']
  e.g. df.columns=['덧셈', '뺄셈','곱셈','나눗셈']

- 데이터프레임의 인덱스 이름 수정:
  변수명=pd.DataFrame([시리즈1,시리즈2,시리즈3],index=['덧셈', '뺄셈','곱셈','나눗셈'])
  e.g. result=pd.DataFrame([add,sub,mul,div],index=['덧셈', '뺄셈','곱셈','나눗셈'])

=============================================================

<< null 값 처리 >>

- null 값 0으로 채우기 :
  데이터프레임.fillna(채울 값)
    e.g. df_filled_zero=df.fillna(0)

- null 값을 각 열의 평균값으로 채우기 :
  데이터프레임.apply(lambda x:x.fillna(x.mean()), axis=0)
    ==> lambda에서 나온 내용을 df에 apply (적용)함
    ==> axis=0 : 행 방향
    e.g. df_filled_mean=df.apply(lambda x:x.fillna(x.mean()),axis=0)

- null 값을 각 열의 중간값으로 채우기 :
  데이터프레임.apply(lambda x:x.fillna(x.median()), axis=0)
    e.g. df_filled_median=df.apply(lambda x:x.fillna(x.median()),axis=0) 

- null 값이 포함된 행/열 삭제 : 
  데이터프레임.dropna() # 행 삭제
  데이터프레임.dropna(axis=1) # 열 삭제
    e.g. df_dropped_rows=df.dropna()
    ==> default로 axis=0이어서 (행에 적용) 함수에서 누락되어 보임
    ==> axis=1로 하면 열에 적용됨

- null 값을 앞의 값으로 채우기 :
  데이터프레임.fillna(method='ffill')
    e.g. df_ffill=df.fillna(method='ffill')

- null 값을 뒤의 값으로 채우기 :
  데이터프레임.fillna(method='bfill')
    e.g. df_bfill=df.fillna(method='bfill')

- replace 메서드로 대체 :
  데이터프레임.replace(기존 값, 대체하고자하는 값)
    e.g. df_replace_zero=df.replace(np.nan,0)


=============================================================

<< 특정 열 조건에 해당되는 행만 선택 >>

변수명1=변수명2[변수명2['열이름']조건]
e.g. df2_sel=df2[df2['Math']>=80]
     print(df2_sel)
     ==> df2 테이터프레임에서 Math 열의 값이 80 이상인 케이스만 df2_sel 에 담아서 출력

<< 특정 열 기준으로 소팅 >>
소팅 방식 여러개 있음

A) 새로 변수 만들어서 소팅 
- 오름차순
    변수명1=변수명2.sort_values(by="열이름")
- 내림차순
    변수명1=변수명2.sort_values(by="열이름", ascending=False)

B) 기존 변수에서 소팅 & 원본에 반영
- 오름차순
    변수명1.sort_values(by"열이름", inplace=True)
    e.g. df2_sel.sort_values(by="English", inplace=True)
- 내림차순
    변수명1.sort_values(by"열이름", ascending=False, inplace=True)
    e.g. df2_sel.sort_values(by="English", ascending=False, inplace=True)

=============================================================

<< 인덱싱 >>
DataFrame과 Series에서 데이터의 특정 위치나 라벨에 접근하기 위한 중요한 도구이며 두 메서드는 각각 고유한 용도를 가지고 있음

iloc (Integer Location)
- 정수 인덱스 기반으로 데이터에 접근하는 메서드. 즉, DataFrame이나 Series의 특정 위치에 있는 데이터를 선택할 때 사용.
- 슬라이싱 지원: Python 리스트와 유사하게 슬라이싱을 지원.
- 끝점 포함하지 않음: 슬라이싱 시 끝점은 포함하지 않는다.
- 기본 형태:
    변수명.iloc[행 인덱스, 열 인덱스]
    변수명.iloc[행 인덱스 시작점:끝점, 열 인덱스 시작점: 끝점])
    e.g. print(df.iloc[0,1])
    e.g. print(df.iloc[0:2,0:2])
    print(df.iloc[1],'\n') 
    # [] 안에 1개의 값만 있다면 행을 뜻함. 따라서 2번째 인덱스 (d2)에 있는 pd, sales, inv 값이 출력됨  

loc (Label Location)
- 라벨 인덱스 기반으로 데이터에 접근하는 메서드. 즉, DataFrame이나 Series의 라벨 이름을 사용하여 데이터에 접근.
- 슬라이싱 지원: 라벨을 사용하여 슬라이싱을 지원.
- 끝점 포함: 슬라이싱 시 끝점을 포함.
- 기본 형태:
    변수명.iloc[행 인덱스, 열 인덱스]
    변수명.iloc[행 인덱스 시작점:끝점, 열 인덱스 시작점: 끝점])
    e.g. print(df.loc['a','B'])
    e.g. print(df.loc['a':'b','A':'B'])

=============================================================

<< 넘파이 랜덤 함수 >>





=============================================================

<< 배열로 변환 >>
  변수명1=변수명2.to_numpy()
  e.g. array2=df2_sorted.to_numpy()

<< 배열 -> 리스트 >>
  변수명1=변수명2.values.tolist()
  e.g. list2=df2_sorted.values.tolist()

<< 배열 -> 딕셔너리 >>
  변수명1=변수명2.to_dict('키 이름')
    e.g.dict=df1.to_dict('list')
    


=============================================================

<< 날짜 범위로 인덱스 만들기 >>

변수명=pd.date_range('시작날짜', periods=생성할 개수, freq='얼마 단위로')




=============================================================

<< 데이터프레임 연산 >>

---- [ 시리즈 더하기 ] ----

- 시리즈 더해서 데이터프레임 만들기

  pd.DataFrame(시리즈1+시리즈2)
  e.g. st1=pd.Series({'국어': 100, '영어': 80, '수학': 90})
       st2=pd.Series({'수학': 80, '국어': 90, '영어': 80})
       pd.DataFrame(st1+st2)

  변수명=시리즈1+시리즈2
  e.g. add=st1+st2
       ==> 변수에다가 시리즈 연산을 담아 계산 시키는 것도 가능



-----

데이터프레임에 들어 있는 각 요소를 특정 인자로 일괄 계산 가능
단, 아래 방법은 해당 인자를 기준으로 연산이 진행됨

- 나누기
  데이터프레임.rdiv(인자)
  ==> 인자/요소 에 대한 계산 값이 데이터프레임에 반영됨
      e.g. df1.rdiv(1)
           ==> 값은 다음과 같이 계산되어 나옴: 1/요소

-----
누적 합 구하기:
.cumsum() 

.expanding().sum()
e.g. cum_sum=s.expanding().sum()

누적 평균 구하기:
.expanding().mean()
e.g. cum_mean=s.expanding().mean()

=============================================================

<< 데이터프레임에서 평균 구하기 >>

- 특정 행의 평균 값 구하기
    데이터프레임[column].mean()
      e.g.  columns=['Math','English', 'Science','History'] 
            ==> name을 제외한 column 들에 적용하기 위해 따로 리스트 만들어주고
            for column in columns: 
                df2[column].fillna(df2[column].mean(),inplace=True) 
                ==> null이 있는 곳에 각 column의 mean값 대체, 원본에 반영

    변수명=데이터프레임.groupby('열이름')['열이름'].mean().sort_values()
    ==> 특정 열이름 기준으로 특정 열이름에 대한 value의 평균 값 구하고 value 기준으로 소팅


- 특정 행만 제외하고 각 열의 평균 값 구하기
      e.g. df2=df1.copy()
           for column in df2.select_dtypes(include=[np.number]).columns:
           ==> datatype이 숫자인 열만 선택해서 아래 내용을 적용해줌 
               df1[column].fillna(df2[column].mean(), inplace=True)

- 특정 기준으로 평균 계산 
    변수명2=데이터프레임1['열이름1'].groupby(데이터프레임1['열이름2'].mean()
      e.g. g=df3['Score'].groupby(df3['Name']).mean()


=============================================================

<< transform 함수 >>
- 원소의 본래 행 인덱스와 열 이름을 기준으로 연산 결과를 반환

기본 형태:
  그룹객체명.transform(매핑함수)
  ==> 내장 함수 사용 시 .transform('내장함수') 와 같이 '' 표기로 넣어줘야 함 

- 그룹별 평균 구하기:
  e.g. df1['mean_by_category']=df1.groupby('Category')['Value'].transform('mean')

- 그룹별 누적합 구하기 :
  e.g. df['Cumulative_Sum']=df.groupby('Category')['Value'].cumsum()
       ==> df 데이터프레임에 'Cumulative_Sum' 열을 추가하는데,
           추가한 열에는 각 'category'별로 'value'에 들어가 있는 값이 누적합이 되어 들어가야함

- 그룹별 누적 평균 구하기 :
  e.g. df['cum_mean']=df.groupby('Category')['Value'].transform(lambda x:x.expanding().mean())
       ==> df 데이터프레임에 'cum_mean' 열을 추가하는데,
           'Category'를 그룹을 묶고, 
           묶인 그룹별로 'Value'열의 값에 대해 transform 함수대로 적용을 시키는데,
           transform 함수에 있는 내용은, 각 행별로 누적 평균을 구해서 적용시키는 것.

=============================================================

<< 그룹 연산 >>
배너처럼 올려서 해당 그룹별로 데이터를 보고 싶을 때 쓰는 방식

- 그룹 생성 및 활용 
기본 형태: 
  그룹객체명=데이터프레임.groupby(['열이름']) 
  e.g.  df1=df[['age','fare','survived','class']]
        grouped=df1.groupby(['class'])

활용 예시:
1. 그룹 객체를 iteration으로 출력하여 각 그룹에 대한 정보를 개별 확인하고 싶을 때:
    for key, group in grouped:
      print('* key : ',key)
      print('* number : ',len(group))
      print(group.head())    
      ==> for문을 사용해서 grouped로 묶인 해당 열에 해당되는 묶음 별로
          (e.g. class의 경우 first, second, third로 이루어져 있음)
          key (grouped 내의 묶음 e.g. first), number (각 그룹의 n수), 보고자 하는 데이터 (e.g. df1)
  
2. 그룹 별 평균 값 보기
    변수명=그룹객체명.mean()
    e.g. average=grouped.mean()
    ==> group별로 각 열에 대한 mean값 나옴

3. 개별 그룹 선택
    그룹=그룹객체명.get_group('그룹 객체에 속한 group이름')
    e.g. group3=grouped.get_group('Third')

4. 그룹 객체의 특정 group에 대한 통계학적 정보:
    변수명.describe()
    e.g. group3.describe()

5. 각 그룹에 대한 모든 열의 표준편차 집계, 데이터프레임으로 반환
    변수명=그룹객체명.std()
    e.g. std_all=grouped.std()

6. 각 그룹에 대한 특정 열의 표준편차를 집계하여 시리즈로 반환
    변수명=그룹객체명.열이름.std()
    e.g. std_fare=grouped.fare.std()

7. 그룹별로 누적 합 구하기
    데이터프레임.groupby('열이름')['더하기 할 열이름'].cumsum()
    e.g. df['Cumulative_Sum']=df.groupby('Category')['Value'].cumsum()

8. 최빈값 구하기
    - 그룹별 최빈값만 간단히 보고 싶다면:
      데이터프레임.groupby(by=['기준 열이름'][['최빈값 찾을 열이름']].agg(pd.Series.mode)
      e.g. df1 = df.groupby(by=['Category'])[['Value']].agg(pd.Series.mode)

    - 그룹의 각 요소와 함께 최빈값을 열추가하여 보고 싶다면 (기존 포맷 유지):
      ==> 사용자 함수 만들어서 사용
      e.g. def most_frequent(x):
           return x.mode().iloc[0]  
             ==> 최빈값이 여러 개일 경우 첫번째 값 선택
           df['Most_Frequent']=df.groupby('Category')['Value'].transform(most_frequent)
             ==> 'Category' 열을 기준으로 그룹화하고, 'Value' 열에 대해 가장 자주 등장하는 값 찾기


- agg() 메서드 사용 

1. 사용자 정의 함수로 인수 전달 :
   def 사용자정의함수(인자):
      return 기능
   변수명=그룹객체명.agg(사용자정의함수)

   e.g. def min_max(x): # 최대값 - 최소값 구하는 함수 생성
        return x.max()-x.min()
        agg_minmax=grouped.agg(min_max) # 그룹객체에 적용한 열 별 최대-최소값
        ==> 결과값으로 각 그룹의 각 열에 대한 max-min 값이 출력되어 데이터프레임 형태로 나옴

2. 내장함수 사용 :
    변수명=그룹객체명.agg(['내장함수1','내장함수2',...])
    ==> 내장함수는 str 형태로 ' ' 붙여줘야 작동함
    e.g. agg_all=grouped.agg(['min','max','mean']) 

3. 각 열마다 다른 함수 적용 :
    변수명=그룹객체명.agg({'열이름':'내장함수','열이름':['내장함수',사용자함수],...})
    ==> 하나의 열에 여러개의 함수 적용 가능
        ==> 이 경우 [] 로 묶어줘야 함
    ==> 사용자함수는 ' ' 붙이지 않음
    e.g. agg_sep=grouped.agg({'fare':['min','max'],'age':'mean'})

4. 특정 조건으로 필터링 :
    변수명=그룹객체명.filter(lambda x:조건)
    e.g. grouped_filter=grouped.filter(lambda x:len(x)>=200)
         ==> 데이터 개수가 200개 이상인 그룹만 필터링하여 데이터프레임으로 반환

5. 그룹별 count 구하기 :
   변수명.value_counts('열이름')
   ==> 해당 열의 그룹 별 데이터 개수 카운트하여 반환
   e.g. grouped_filter.value_counts('class')

=============================================================

<< 함수 매핑 >>
커스텀 함수(custom function)를 DataFrame에 적용하려면 map함수, apply함수, applymap함수를 사용
  - map 함수 : Series의 각 요소에 함수를 적용
  - apply 함수 : Series 또는 DataFrame의 행이나 열에 함수를 적용
  - applymap 함수 : DataFrame의 각 요소에 함수를 적용

[ apply vs map ]
- apply는 DataFrame의 행이나 열 단위로 함수를 적용할 수 있지만, map은 Series의 각 요소에만 함수를 적용
- Series의 각 요소를 변환하는 간단한 작업에는 map이 적합하고, 더 복잡한 변환이 필요한 경우나 DataFrame 전체를 다룰 때는 apply가 유용

[ apply vs applymap ]
- df.apply는 DataFrame의 각 행(row) 또는 열(column)에 함수를 적용 
- 기본적으로 axis=0으로 설정되어 있어 열 단위로 함수를 적용
- 각 행 또는 열 자체가 Series로 전달되며, 이 Series 전체에 대해 함수를 적용하려고 한다.
- applymap은 DataFrame의 모든 요소에 대해 함수를 적용하므로, 전체 DataFrame에 대한 변환이 필요할 때 유용

1. map 함수 :
- 시리즈 더하기
e.g. s=pd.Series([1,2,3,4,5])
     s_mapped=s.map(lambda x:x+2)
- 특정 열의 포맷 수정 :
e.g. format=lambda x:'%.2f' %x
     frame['e'].map(format)


2. apply 함수 :
데이터프레임의 행/열 단위로 적용됨


- 각 열에 대한 최대값 구하기
e.g. df_applied_col=df.apply(lambda x:x.max(), axis=0)
     ==> 각각의 열에 대한 최대값을 봐야하니 axis=0인 행 방향으로 봐야함 (열을 기준으로 행을 살펴봄)

- 각 행에 대한 합계 구하기
e.g. df_applied_row = df.apply(lambda x:x.sum(),axis=1)

- 시리즈의 최대, 최소값 차이 계산
e.g. f=lambda x:x.max()-x.min()
     frame.apply(f)
     ** 각 행에 대해 한번씩 수행하고 싶다면 axis='columns' 추가해주면 됨
         e.g. frame.apply(f,axis='columns')



3. applymap 함수 : 
데이터프레임 전체에 일괄 적용됨
시리즈에는 사용 못함 

- 각 요소에 2를 더하기
e.g. df=pd.DataFrame({
    'A': [1,2,3],
    'B': [4,5,6],
    'C': [7,8,9]
      })
    df_applymapped=df.applymap(lambda x:x+2)
    ==> 각 요소에 현재 값에서 2를 일괄적으로 더해줌


=============================================================

<< 피벗 (pivot) 함수 >>
[[ 구성 ]]
- index: 새로운 DataFrame에서 인덱스로 사용할 기존 열 또는 열들의 이름.
- columns: 새로운 DataFrame에서 열로 사용할 기존 열 또는 열들의 이름.
- values: 피벗할 때 사용할 값이 있는 열의 이름.

[[ 기능 ]]
- 긴 형식의 데이터를 넓은 형식으로 변환하여 특정 차원에서 데이터를 재구성.
- 피벗된 데이터를 통해 시간 경과에 따른 변화나 여러 카테고리의 비교를 쉽게 할 수 있다.
- 넓은 형식의 데이터는 시각화 도구에서 더 쉽게 다룰 수 있다.


기본 형태:
  변수명=데이터프레임.pivot(index='행으로 볼 열이름', columns='열로 볼 열이름', values='보려는 값의 열이름')
  e.g. data = {
       'date': ['2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02'],
       'city': ['New York', 'Los Angeles', 'New York', 'Los Angeles'],
       'temperature': [32, 75, 30, 78]
        }
        df=pd.DataFrame(data)
        pivot_df=df.pivot(index='date', columns='city', values='temperature')

- 중복 값 평균 처리하여 피벗 생성:
  변수명=데이터프레임.pivot(index='행으로 볼 열이름', columns='열로 볼 열이름', values='보려는 값의 열이름', aggfunc='mean')
  e.g. pivot_table_df=df.pivot_table(index='date',columns='city',values='temperature',aggfunc='mean')

- 다중 인덱스와 다중 값 사용:
  ==> 여러 값을 볼 생각이라면 index, columns만 지정해주면 됨
  변수명=데이터프레임.pivot(index='행으로 볼 열이름', columns='열로 볼 열이름')
  e.g. pivot_multi_df=df.pivot(index='date', columns='city')

- 합계를 구하고 싶다면:
  변수명=데이터프레임.pivot(index='행으로 볼 열이름', columns='열로 볼 열이름', values='보려는 값의 열이름', aggfunc='sum', fill_value=0)
  e.g. pivot_table_1=df.pivot_table(index='Year', columns='Product', values='Sales', aggfunc='sum', fill_value=0)


<< crostab >> 

변수명=pd.crosstab(데이터프레임['열이름'], 데이터프레임['열이름'])

e.g. party_counts=pd.crosstab(tips['day'], tips['size'])

==> 결과 : 
size	1	2	3	4	5	6
day						
Fri	1	16	1	1	0	0
Sat	2	53	18	13	1	0
Sun	0	39	15	18	3	1
Thur	1	48	4	5	1	3
=============================================================

<< 파일 만들기 >>

[[ CSV 파일 생성 ]]
파일명.to_csv('파일명.csv', index=None)
==> None을 넣지 않으면 인덱스 행이 중복되어 나옴
e.g. file_data.to_csv('file_data.csv',index=None)


=============================================================

<< 피벗 만들어서 정리 >>
데이터프레임.pivot_table(index='열이름', columns='열이름', values='열이름', aggfunc='집계 기준')
  ==> aggfunc= 집계하는 숫자는 mean으로 하라, 는 뜻
  e.g. df3.pivot_table(index='Name',columns='Subject',values='Score',aggfunc='mean')



=============================================================

<< 공공데이터 소스 >>
https://www.data.go.kr/





