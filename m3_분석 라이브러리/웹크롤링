<<< 웹사이트 구조 >>>
- 

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title> # 태그 사이에 Document 는 해당 웹사이트의 제목   
</head>
<body>
    <h1>"Hello World!"</h1> # h 뒤 숫자로 웹에서 글씨 크기 조정 
</body>
</html>


==============================================

HTML 문서는 다음과 같은 DOM 트리로 표현
```
Document
└── html
    ├── head
    │   ├── title
    │   │   └── "Example"
    └── body
        ├── h1
        │   └── "DOM Example"
        └── p (id="intro")
            └── "This is a simple DOM example."

==============================================

#### HTML 태그

```
기본 구조 태그
<!DOCTYPE html>: HTML 문서의 유형을 정의합니다. 최신 HTML5에서는 <!DOCTYPE html>을 사용합니다.
<html>: HTML 문서의 루트 요소입니다. 모든 HTML 문서의 최상위 요소입니다.
<head>: HTML 문서의 메타데이터를 포함합니다. 여기에는 문서 제목, 스타일 시트 링크, 스크립트 등이 포함됩니다.
<title>: 웹 페이지의 제목을 정의합니다. 이 제목은 브라우저 탭에 표시됩니다.
<meta>: 문서의 메타데이터를 정의합니다. 예를 들어, 문자 인코딩을 정의할 때 사용됩니다.
<link>: 외부 리소스를 문서에 연결합니다. 주로 CSS 파일을 연결할 때 사용됩니다.
<style>: 문서 내에 CSS 스타일을 정의합니다.
<body>: 실제로 브라우저에 표시되는 콘텐츠를 포함합니다.
```
```
콘텐츠 구조 태그
<header>: 문서나 섹션의 헤더를 정의합니다.
<nav>: 내비게이션 링크를 정의합니다.
<section>: 문서의 섹션을 정의합니다.
<article>: 독립적인 콘텐츠를 정의합니다.
<aside>: 주요 콘텐츠 외의 추가적인 콘텐츠를 정의합니다.
<footer>: 문서나 섹션의 푸터를 정의합니다.
```
```
텍스트 관련 태그
<h1> ~ <h6>: 제목을 정의합니다. <h1>은 가장 중요한 제목, <h6>은 가장 덜 중요한 제목입니다.
<p>: 단락을 정의합니다.
<a>: 하이퍼링크를 정의합니다. href 속성을 사용하여 링크 대상 URL을 지정합니다.
<strong>: 중요한 텍스트를 정의합니다. 일반적으로 굵게 표시됩니다.
<em>: 강조된 텍스트를 정의합니다. 일반적으로 기울임꼴로 표시됩니다.
<br>: 줄 바꿈을 삽입합니다.
<ul>: 순서 없는 목록을 정의합니다.
<ol>: 순서 있는 목록을 정의합니다.
<li>: 목록 항목을 정의합니다.
```
```
멀티미디어 태그
<img>: 이미지를 삽입합니다. src 속성을 사용하여 이미지 파일의 URL을 지정합니다.
<audio>: 오디오 콘텐츠를 삽입합니다.
<video>: 비디오 콘텐츠를 삽입합니다.
<iframe>: 다른 HTML 페이지를 현재 페이지에 삽입합니다.
```
```
테이블 태그
<table>: 표를 정의합니다.
<tr>: 표의 행을 정의합니다.
<td>: 표의 셀을 정의합니다.
<th>: 표의 헤더 셀을 정의합니다.
<thead>: 표의 머리글 섹션을 정의합니다.
<tbody>: 표의 본문 섹션을 정의합니다.
<tfoot>: 표의 바닥글 섹션을 정의합니다.
```
```
폼 태그
<form>: 사용자 입력을 받는 폼을 정의합니다.
<input>: 다양한 유형의 입력 필드를 정의합니다.
<textarea>: 여러 줄의 텍스트 입력 필드를 정의합니다.
<button>: 클릭 가능한 버튼을 정의합니다.
<select>: 드롭다운 목록을 정의합니다.
<option>: 드롭다운 목록의 항목을 정의합니다.
```


==============================================

#### HTML 속성
- HTML 속성(Attribute)은 HTML 요소에 추가적인 정보를 제공하는 데 사용됩니다. 
- 속성은 시작 태그 내에 있으며, 이름-값 쌍으로 작성됩니다.<br>
    ```<a href="https://example.com" class="example-link">Example</a>```
- 각 속성은 요소의 특정 특성이나 동작을 정의합니다. 
    ```
    - <a>: 앵커 태그로, 하이퍼링크를 만듭니다.
    - href: 링크의 URL을 지정하는 속성입니다.
    - class: CSS 클래스를 지정하는 속성입니다.
    ```
- 속성의 값은 일반적으로 따옴표로 감싸지만, 따옴표 없이 작성할 수도 있습니다.
- HTML 속성의 기본 구조 :<br>
    ```<a href="https://www.example.com" target="_blank">Example Link</a>``` 
              => target="_blank" : 새 탭에서 열리도록 함

  여기서 a 태그는 두 개의 속성을 가집니다:
    ```
    href: 링크의 URL을 지정
    target: 링크를 여는 방식 지정 (_blank는 새 탭에서 열기)
    ```
- 주요 HTML 속성

    글로벌 속성 (Global Attributes): 거의 모든 HTML 요소에서 사용할 수 있는 속성들입니다.<br>    
    ```<div id="header" class="main-header" style="color: blue;" title="Header Section">Welcome!</div>```
    - id: 요소의 고유 식별자 # 해당 문서에서 한 번만 사용 가능
    - class: CSS 클래스 지정 # css 클래스로 사용되며 중복 가능
    - style: 인라인 CSS 스타일 지정 # 외부 링크에서 사용 가능. 태그 안에서 사용될 경우 인라인 css. 
    - title: 요소에 대한 추가 정보 제공 (마우스를 올렸을 때 표시) 
    - data-*: 페이지나 애플리케이션에 사용자 정의 데이터를 저장

    폼 속성 (Form Attributes): 주로 폼 요소에서 사용되는 속성들입니다.
    ```
    <form action="/submit" method="post"> # submit 클릭 후 어디로 이동될지 지정. 
                                          # post : 바디 안에 넣어서 요청이 노출되지 않도록 지정. post 대신 get도 사용 간으하나 노출됨)
      <input type="text" name="username" value="JohnDoe" placeholder="Enter your username">
              # input : 입력 창 만들어줌
              # type : 인풋하는 방식
              # placeholder : 안내멘트 (개발자가 사용자에게 해당 기능 사용 시 전달하고싶은 안내 멘트.
      <input type="submit" value="Submit"> # type="submit": 이 입력 필드를 제출 버튼으로 정의
    </form>
    ```
    - action: 폼 제출 시 데이터를 전송할 URL
    - method: 폼 데이터 전송 방식 (GET, POST)
    - name: 폼 요소의 이름
    - value: 입력 요소의 초기 값
    - placeholder: 입력 필드에 표시되는 힌트 텍스트

    이미지 속성 (Image Attributes): 주로 이미지 요소에서 사용되는 속성들입니다.<br>
    ```<img src="image.jpg" alt="Example Image" width="200" height="100">```
    - src: 이미지 파일의 경로
    - alt: 이미지가 표시되지 않을 때 대체 텍스트
    - width와 height: 이미지의 크기 지정

    링크 속성 (Link Attributes): 주로 앵커(a) 태그에서 사용되는 속성들입니다.<br>    
    ```<a href="https://www.example.com" target="_blank" rel="noopener noreferrer">Visit Example</a>```
    - href: 링크의 URL
    - target: 링크를 열 방법 (_blank, _self, _parent, _top) 
    - rel: 링크와 현재 문서 간의 관계

    메타 데이터 속성 (Metadata Attributes): 주로 meta 태그에서 사용되는 속성들입니다.
    ```
    <meta name="description" content="This is an example of a meta description.">
    <meta charset="UTF-8">
    ```
    - name: 메타 데이터의 이름 (예: description, keywords)
    - content: 메타 데이터의 내용
    - charset: 문서의 문자 인코딩



==============================================

#### CSS 셀렉터

CSS 셀렉터는 HTML 요소를 선택하기 위해 사용됩니다. 크롤링 시 특정 요소를 선택할 때 유용합니다. 예:
```
#id: 특정 id를 가진 요소를 선택합니다.
.class: 특정 클래스를 가진 요소를 선택합니다.
tagname: 특정 태그명을 가진 요소를 선택합니다.
```
```
[ CSS 셀렉터의 주요 유형과 그 사용법]

1. 기본 셀렉터
    요소 셀렉터
    문법: element
    설명: 지정된 태그 이름의 모든 HTML 요소를 선택합니다.
    예시: p { color: blue; }는 모든 <p> 요소의 텍스트 색상을 파란색으로 설정합니다.
    클래스 셀렉터
    문법: .class
    설명: 특정 클래스 이름을 가진 모든 요소를 선택합니다.
    예시: .highlight { background-color: yellow; }는 클래스가 "highlight"인 모든 요소의 배경색을 노란색으로 설정합니다.
    ID 셀렉터
    문법: #id
    설명: 특정 ID를 가진 요소를 선택합니다. HTML 문서에서 ID는 고유해야 합니다.
    예시: #header { font-size: 24px; }는 ID가 "header"인 요소의 글꼴 크기를 24px로 설정합니다.

2. 속성 셀렉터
    속성 존재 셀렉터
    문법: [attribute]
    설명: 특정 속성이 있는 모든 요소를 선택합니다.
    예시: [title] { border: 1px solid black; }는 "title" 속성이 있는 모든 요소에 테두리를 추가합니다.
    특정 속성 값 셀렉터
    문법: [attribute=value]
    설명: 지정된 속성이 특정 값을 가진 모든 요소를 선택합니다.
    예시: [type="text"] { color: green; }는 type 속성이 "text"인 모든 입력 요소의 텍스트 색상을 초록색으로 설정합니다.

3. 결합 셀렉터
    자손 셀렉터
    문법: ancestor descendant
    설명: 특정 요소의 자손인 모든 요소를 선택합니다.
    예시: div p { margin: 10px; }는 <div> 요소의 자손인 모든 <p> 요소에 10px의 마진을 설정합니다.
    자식 셀렉터
    문법: parent > child
    설명: 특정 요소의 직계 자식인 모든 요소를 선택합니다.
    예시: ul > li { list-style-type: none; }는 <ul> 요소의 직계 자식인 모든 <li> 요소의 리스트 스타일을 제거합니다.
    인접 형제 셀렉터
    문법: element + adjacent
    설명: 특정 요소의 바로 다음 형제 요소를 선택합니다.
    예시: h1 + p { margin-top: 0; }는 <h1> 요소 바로 다음에 오는 <p> 요소의 위쪽 마진을 제거합니다.
    일반 형제 셀렉터
    문법: element ~ siblings
    설명: 특정 요소 이후의 모든 형제 요소를 선택합니다.
    예시: h2 ~ p { color: grey; }는 <h2> 요소 이후의 모든 <p> 요소의 텍스트 색상을 회색으로 설정합니다.

4. 가상 클래스 셀렉터
    동적 가상 클래스 셀렉터
    문법: :pseudo-class
    설명: 요소의 특정 상태를 선택합니다.
    예시: a:hover { color: red; }는 링크에 마우스를 올렸을 때 텍스트 색상을 빨간색으로 변경합니다.
    구조적 가상 클래스 셀렉터
    문법: :nth-child(n)
    설명: 부모 요소의 자식 중 특정 위치에 있는 요소를 선택합니다.
    예시: li:nth-child(odd) { background-color: #f2f2f2; }는 홀수 번째 <li> 요소의 배경색을 회색으로 설정합니다.

5. 가상 요소 셀렉터
    문법: ::pseudo-element
    설명: 요소의 일부를 선택합니다.
    예시: p::first-line { font-weight: bold; }는 단락의 첫 번째 줄을 굵게 만듭니다.

6. 속성값 서브스트링 매칭 셀렉터
    시작 문자열 매칭 셀렉터
    문법: [attribute^=value]
    설명: 특정 속성 값이 지정된 문자열로 시작하는 요소를 선택합니다.
    예시: [class^="btn"] { background-color: blue; }는 클래스 이름이 "btn"으로 시작하는 모든 요소의 배경색을 파란색으로 설정합니다.
    끝 문자열 매칭 셀렉터
    문법: [attribute$=value]
    설명: 특정 속성 값이 지정된 문자열로 끝나는 요소를 선택합니다.
    예시: [class$="danger"] { color: red; }는 클래스 이름이 "danger"로 끝나는 모든 요소의 텍스트 색상을 빨간색으로 설정합니다.
    포함 문자열 매칭 셀렉터
    문법: [attribute*=value]
    설명: 특정 속성 값이 지정된 문자열을 포함하는 요소를 선택합니다.
    예시: [class*="nav"] { font-size: 18px; }는 클래스 이름에 "nav"를 포함하는 모든 요소의 글꼴 크기를 18px로 설정합니다.

```

==============================================

## 크롤링(웹 크롤링)
크롤링이란
- 인터넷 상의 웹 페이지 데이터를 자동으로 수집하는 과정.
- 웹 크롤링은 일반적으로 웹 스크래핑과 연관되며, 둘은 종종 혼용되지만 조금 다른 개념. 웹 크롤링은 웹 페이지를 탐색하고 데이터를 수집하는 반면, 웹 스크래핑은 그 페이지에서 특정 정보를 추출하는 데 중점을 둔다.
- 크롤링은 스크래핑을 포함할 수 있다. 크롤링 과정에서 각 페이지를 방문할 때, 스크래핑을 통해 필요한 데이터를 추출할 수 있다.

웹 크롤링에 사용되는 도구
- BeautifulSoup: Python 라이브러리로, HTML 및 XML 문서를 구문 분석하고 데이터를 추출하는 데 사용.

- Scrapy: 웹 크롤링을 위한 Python 프레임워크로, 효율적이고 확장성이 높은 크롤러를 쉽게 만들 수 있다.

- Selenium: 웹 브라우저 자동화 도구로, JavaScript가 동적으로 로드되는 페이지를 크롤링할 때 유용.

- Requests: Python의 HTTP 라이브러리로, 웹 페이지 요청을 쉽게 할 수 있다.

웹 크롤링의 기본 과정
- 크롤러 설정: 크롤러는 특정 웹 페이지를 시작점으로 설정. 이를 '시드(seed)'라고 부르며, 크롤러는 이 시드 URL에서 시작해 다른 페이지로 이동.

- 페이지 요청: 크롤러는 HTTP 요청을 보내 웹 페이지를 요청. 이 과정에서 크롤러는 브라우저처럼 행동하여 웹 서버에서 페이지를 가져온다.

- 데이터 추출: 웹 페이지가 응답되면, 크롤러는 페이지의 HTML을 분석하고 필요한 데이터를 추출. 이 과정에는 BeautifulSoup, Selenium 같은 라이브러리가 사용될 수 있다.

- 링크 추출 및 큐잉: 크롤러는 현재 페이지에서 다른 페이지로 연결되는 링크를 추출하고, 이 링크들을 큐(queue)에 추가하여 다음 크롤링 대상으로 삼는다.

- 반복: 이 과정은 정해진 규칙이나 종료 조건이 충족될 때까지 반복. 예를 들어, 특정 수의 페이지를 크롤링하거나, 주어진 도메인 내에서만 크롤링하도록 설정할 수 있다.

웹 크롤링의 주의사항

- 로봇 배제 표준(robots.txt): 많은 웹사이트는 robots.txt 파일을 통해 크롤러가 접근 가능한 부분과 접근을 제한하는 부분을 명시. 크롤러는 이 규칙을 준수해야 한다.

- 저작권 및 법적 이슈: 모든 웹사이트의 콘텐츠는 저작권의 보호를 받는다. 따라서 크롤링을 통해 수집한 데이터를 어떻게 사용할지에 대한 법적 문제를 주의해야 한다.

- 서버 부하: 지나친 크롤링은 웹 서버에 부하를 줄 수 있다. 크롤링 시에는 서버의 부담을 줄이기 위해 요청 간의 딜레이를 설정하는 것이 좋다.

==============================================

<< BeautifulSoup 사용하여 웹크롤링 >>


- 불러온 html 문서를 파싱을 통해 다루기 쉽게 만들어야 함
변수명=Beautifulsoup(html_doc, 'html.parser')



<< 태그 찾기 >>

*** 띄어쓰기 주의 필요 

.find('찾을 내용') : 1개만 찾음 
e.g. tag=soup.find(id='1234')

.find_all('찾을 내용') : 해당되는 여러개의 태그를 찾음
e.g. tag=soup.find_all(class_='abcde')


.select('찾을 css 설렉터') : css 설렉터로 해당되는 것을 모두 불러옴. 
                            id의 경우 '#id이름', 
                            클래스의 경우 '.클래스이름' 처럼 
                            불러올 정보 타입에 따라 특정 기호가 붙음
e.g. u_skip_links=soup.select('#u_skip a') # id가 u_skip의 a 모두 찾기
     for link in u_skip_links:
         print(link.text) # 텍스트만

.select_one('찾을 css 설렉터') : 상동
                                ** 다만, 해당되는 것 중 첫번째꺼만 보여줌
u_skip_links=soup.select('#u_skip')


특정 id 아래 속한 id 찾기: 
header_div=soup.select_one('#wrap #header')
print(header_div.text if header_div else 'No header div found')
==> wrap 의 하위 아이디 header 를 찾는데,
    있으면 header에 속한 내용을 텍스트로 반환,
    없다면 "No header div found' 내용을 대신 출력


----- [         ] -----

.get('href') : <a> 에 붙은 href (url) 불러오기
변수명['href'] : <a> 에 붙은 href (url) 불러오기


----- [ 속성으로 찾기 ] -----

attrs={'속성':'속성 값'} 

e.g. #  data-gfp-banner-size 속성을 가진 태그 추출
        banners=soup.find_all(attrs={'data-gfp-banner-size':'830x130'})
        for banner in banners:
            print(banner.prettify())

e.g. #  위 문제를 id로 찾아 추출 
        banners=soup.find_all(attrs={'id':'ad-timeboard-response'})
        for banner in banners:
            print(banner.prettify())



----- [ 부모/ 형제/ 자손 태그 찾기 ] -----

.find_parent()
.find_parents()
.find_next_sibling()
.find_previous_sibling()
.find_next_siblings()
.find_previous_siblings()
.findChilrden()



----- [ 출력 형식 정돈 ] -----

.prettify() : 불러온 정보 출력 시 정돈된 포맷으로 제공 




----- [ 이메일 형식 가져오기 ] -----

e.g.
import requests
from bs4 import BeautifulSoup
import re

html = """
<ul>
    <li>Email: example@example.com</li>
    <li>Contact: contact@sample.org</li>
</ul>
"""

# 이메일 주소 추출
email_pattern=r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+'
emails=re.findall(email_pattern,html)
print(emails)



----- [ 구분자 추가 ] -----

# 'separator' 매개변수를 사용하여 구분자를 지정
single_text_node_with_separator=soup.find('div', class_='example').get_text(strip=True)
multiple_text_nodes_with_separator=soup.find_all('div', class_='example')[1].get_text(separator=' | ',strip=True)

print("Default separator (' | ') :") 
print(single_text_node_with_separator) # ouptut: Single text node
print(multiple_text_nodes_with_separator) # output: Multiple | text | nodes


----- [ 정규식 표현 사용 ] -----

<< 모든 단어 추출 >>

# \b : 단어 경계, \w : 단어 문자
words_list=''
soup=BeautifulSoup(html, 'html.parser')
words=re.findall(r'\b\w+\b', soup.text) # \b == 단어와 단어가 아닌 것 사이의 경계를 구분해줌
for word in words:
    words_list += word
    words_list += ' '
print(words_list)
==> 결과: Sample Page Hello world 123 456 Hello 789 world Visit us at example com Contact us at info example com 


<< 이메일 주소 추출 >>

email_pattern=r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+'
emails=re.findall(email_pattern,html)
print("이메일 주소 추출:\n",emails,'\n')
==> 결과 : info@example.com


<< url 추출 >>

url_pattern=r'https?://[^\s<>"]+|www\.[^\s<>"]+'
urls=re.findall(url_pattern, html)
for url in urls:
    print(url)


<< 숫자 추출 >>

# \b : 단어 경계, \d : 숫자
nums_list=''
soup=BeautifulSoup(html, 'html.parser')
nums=re.findall(r'\b\d+\b', soup.text) 
for num in nums:
    nums_list += num
    nums_list += ' '
print(nums_list)


<< html 태그 내 텍스트 추출 >>

tag_texts=re.findall(r'>([^<]+)<', html)
text_lists=' '.join(text.strip() for text in tag_texts)
text_lists


tag_texts=re.findall(r'>([^<]+)<', html)
text_lists=re.sub(r'\s+', ' ', text_lists)
text_lists=text_lists.split()
text_lists
==> 결과 : 세로로 word by word로 출력됨


<< 한글만 추출 >>
e.g. 
import re
texts=response.text
result=re.findall('[가-힣]+', texts)
print(' '.join(result))




============================================================

<< 웹사이트에서 데이터 가져올 때 >>
- 총 2가지 방법:
    1. urllib 모듈 사용해서 불러오기
    2. requests 모듈 사용해서 불러오기 

----- [ urllib 사용 ] -----

import urllib.request as rq # url을 다루기 위한 모듈
# http, ftp, smtp 등과 같은 프로토콜을 사용하여 url을 열고 읽고 쓰는 기능을 제공

url='http://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=100'

html=rq.urlopen(url)
bs=BeautifulSoup(html, 'html.parser')
print(bs)


----- [ requests 사용 ] -----

import requests 

url='http://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=100'
html=requests.get(url)
bs=BeautifulSoup(html.text, 'html.parser')
print(bs)


============================================================

개발자 도구상에서 .class로 확인한 정치기사 개수는 58개인 반면 select('.class')로 크롤링한 기사 개수는 38개인 이유:
* 많은 사이트는 JavaScript를 사용하여 콘텐츠를 동적으로 로딩하는 반면 
  requests + BeautifulSoup은 기본적으로 JavaScript를 실행하지 않기 때문에 
  일부 js로 로딩되는 콘텐츠는 크롤링되지 않는다.
* 페이지가 완전히 로드되기 전에 크롤링이 시도될 경우 일부 콘텐츠가 누락될 수 있다.
* 웹페이지가 비동기 요청(Ajax)를 사용하여 데이터를 가져오는 경우 이 요청을 수동으로 처리하지 않는 한 
  해당 데이터를 가져오지 못할 수 있다.




============================================================

<< 파이썬으로 원하는 뉴스 기사 키워드 입력하여 관련 기사 긁어오기 >>
news_url.format(query): URL 문자열 내의 특정 부분을 query 변수의 값으로 대체
- news_url 변수에는 포맷 문자열 'https://news.example.com/search?query={}'가 저장
- news_url.format(query)는 포맷 문자열의 {} 부분을 query 변수의 값으로 대체
- 결과적으로, 포맷팅된 URL은 'https://news.example.com/search?query=politics'가 된다.


e.g. 
from bs4 import BeautifulSoup
import requests
import re
from datetime import datetime
import os

query=input('검색 키워드를 입력하세요 : ')
query=query.replace(' ', '+')
print(query)

news_url='https://search.naver.com/search.naver?where=news&sm=tab_jum&query={}'

# format(query) 메서드는 url 템플릿의 {} 부분을 query로 대체해줌
req=requests.get(news_url.format(query))

html=req.text
soup=BeautifulSoup(html, 'html.parser')
links=soup.select('.news_tit')
# print(links)
for link in links:
    title=link.text
    url=link.attrs['href']
    print(title, '\n', url)



============================================================

<< Selenium - 동적 컨텐츠 찾기 >>

- selenium 사용해서 데이터 가져오기
- 데이터를 '요리'하기 위해서는 beautifulsoup을 주로 사용
    ==> selenium도 사용은 할 수 있으나 시간이 더 오래 걸려서 bs를 더 많이 씀

사용법: 
- from selenium.webdriver.common.by import By

- find_element(By.ID, " "): id 속성을 사용하여 접근
- find_element(s)(By.CLASS_NAME, " "): 클래스를 사용하여 접근
- find_element(s)(By.NAME, " "): name 속성을 사용하여 접근
- find_element(s)(By.XPATH, " "): xpath 속성을 사용하여 접근
- find_element(s)(By.LINK_TEXT, " "): 앵커태그(a 태그)에 사용되는 텍스트로 접근
- find_element(s)(By.PARTIAL_LINK_TEXT, " "): 앵커태그(a 태그)에 사용되는 일부 텍스트로 접근
- find_element(s)(By.TAG_NAME, " "): 태그를 사용하여 접근
- find_element(s)(By.CSS_SELECTOR, " "): CSS 선택자를 사용하여 접근

- driver.forward() : 앞으로 이동
- driver.refresh() : 페이지 리프레시
- driver.back() : 뒤로 이동
- time.sleep(숫자) : '숫자'만큼 쉬기
- driver.find_element(By.OOO, 'OOO').click() : OOO 을 찾아서 클릭
- send_keys('입력창에 입력할 내용') : 입력창에 원하는 내용 입력
- send_keys(Keys.ENTER) : 입력창에 입력한 내용 실행 
- 변수명.get_attribute('속성이름') : find_element로 찾은 것의 특정 속성 가져오기
    e.g. elems=driver.find_elements(By.TAG_NAME, 'a')
         for e in elems:
             print(e.get_attribute('href'))


----- [ selenium 사용 예시 ] -----

e.g. 
# 동적 콘텐츠 로딩 : selenium 사용
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By 
import time

options=Options() # Options 사용을 위한 객체 만들기
options.add_argument("--start-maximized") # 브라우저 화면 최대화 
options.add_experimental_option("detach", True) # 브라우저 화면을 열어서 유지해줌

driver=webdriver.Chrome(options=options) # 웹드라이버 가동

# Naver 페이지 열기 
url='https://www.naver.com/'
driver.get(url)

# 페이지 로딩 대기
time.sleep(2) # 2초 대기 (필요에 따라 조정)

# 뉴스스탠드 링크 찾기

# "F12" > 점선 네모 위에 커서 있는 아이콘 선택 > 네이버 홈 화면의 "뉴스스탠드" 클릭 > 해당되는 파트 자동 하이라이트 된 곳에 우측 클릭 >
# "copy" 클릭 > "Copy selector" 클릭
# copy selector 클릭하면 아래와 같이 경로가 뜸. 해당 경로를 find_element(By.CSS_SELECTOR, 'here') " 'here' " 위치에 붙여 넣기
# newsstand > div.ContentHeaderView-module__content_header___nSgPg > div > ul > li:nth-child(1) > span > a:nth-child(1)

try:
    newsstand_link=driver.find_element(By.CSS_SELECTOR, '#newsstand > div.ContentHeaderView-module__content_header___nSgPg > div > ul > li:nth-child(1) > span > a:nth-child(1)')
    print(newsstand_link.text)
except:
    print("뉴스스탠드 링크를 찾을 수 없습니다")

# 브라우저 닫기
driver.quit()


*** xpath로 찾고 싶다면 By.CSS_SELECTOR 대신 By.XPATH 를 넣어주면 됨


============================================================

<< Javascript >>


Javascript 선택자 : https://hianna.tistory.com/485

1. getElementById()
 - 파라미터로 찾으려는 id를 전달하여, 해당 element를 찾을 수 있습니다. 
 - id는 유일한 값이므로, 하나의 element만 리턴합니다.
2. getElementsByClassName()
 - 클래스 이름으로 element를 찾아서,이 클래스 이름을 가지는 모든 element 목록을 리턴합니다.
 - 이 함수의 이름을 자세히 보면 getElementsByClassName으로 Element's'가 복수 형태인 것은 이 함수가 목록을 리턴하기 때문입니다.
3. getElementByTagName()
 - 위 코드는 'div' 태그를 가지는 모든 element 목록을 찾아줍니다.
 - 이 함수 역시, 다수의 element를 리턴하기 때문에 함수명에 복수형의 'elements'가 포함되어 있습니다.
4. querySelector()
 - DOM에서 원하는 element를 찾기 위해서 querySelector() 를 사용할 수도 있는데, 이 함수는 파라미터로 입력받은 CSS선택자를 사용해서, element를 찾아줍니다.
 - querySelector() 함수는, 파라미터로 입력받은 CSS 선택자로 찾은 여러개의 element 중 첫번째 element를 리턴합니다.
 - 태그 이름으로 element를 찾을 때는 태그명을 문자열로 넘겨줍니다.위 예제는 div태그를 가지는 element 중 첫번째 element를 리턴합니다.
5. querySelectorAll()
 - 사용법은 querySelector() 와 같습니다. 다만, querySelectorAll()은 이름에서 알수 있듯이, CSS선택자(파라미터로 넘겨준)로 찾은 모든 element 목록을 리턴합니다.


e.g 1) 
----- [ DOM 요소 선택 및 텍스트 추출 ] -----

from selenium import webdriver

driver=webdriver.Chrome()
driver.get('http://books.toscrape.com/')

# 첫 번째 책의 제목을 추출
book_title=driver.execute_script("return document.querySelector('article.product_pod h3 a').innerText;")
# article 태그 안에 'product_pod' 클래스의 하위 요소들 중 h3 의 a 태그에 있는 innertext 를 가져오기 
# <a href="catalogue/a-light-in-the-attic_1000/index.html" title="A Light in the Attic">A Light in the ...</a>

print("First book title: ", book_title)
driver.quit()


e.g.2)
----- [  다수의 요소 선택 및 데이터 추출 ] -----
driver=webdriver.Chrome()
driver.get('http://books.toscrape.com/')

# 모든 책 제목 추출
book_titles=driver.execute_script("""
    var elements=document.querySelectorAll('article.product_pod h3 a');
    var data=[];
    elements.forEach(function(element) {
    data.push(element.innerText);
    });
    return data;
    """)
print("Book titles: ", book_titles)
time.sleep(3)
driver.quit()


e.g.3)
----- [ DOM 요소 선택 및 속성 추출 ] -----

# 속성은 .getAttribute('속성이름') 사용
from selenium import webdriver

driver=webdriver.Chrome()
driver.get('http://books.toscrape.com/')

# 첫 번째 책의 url을 추출
book_url=driver.execute_script("return document.querySelector('article.product_pod h3 a').getAttribute('href');")
print("First book url: ", book_url)
driver.quit()


e.g.4) 
----- [ 스크롤 이벤트 트리거 ] -----

driver=webdriver.Chrome()
driver.get('http://books.toscrape.com/')

# 페이지 맨 아래로 스크롤
driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
time.sleep(5)
driver.quit()


e.g.5)
----- [ 클릭 이벤트 트리거 ] -----

import time
driver=webdriver.Chrome()
driver.get('http://books.toscrape.com/')

# 첫번째 책의 링크 클릭
driver.execute_script("document.querySelector('article.product_pod h3 a').click();")
time.sleep(2)
driver.quit()


e.g.6)
----- [ 스타일 변경 ] -----

driver=webdriver.Chrome()
driver.get('http://books.toscrape.com/')

# 첫번째 책의 배경색 변경
driver.execute_script("document.querySelector('article.product_pod').style.backgroundColor='yellow';")
time.sleep(3)
driver.quit()


===================================

<< JavaScript >>
- document.getElementById(id) : 특정 ID를 가진 요소를 선택합니다.
- document.getElementsByClassName(className) : 특정 클래스 이름을 가진 요소를 선택합니다.
- document.getElementsByTagName(tagName) : 특정 태그 이름을 가진 요소를 선택합니다.
- document.querySelector(selector) : CSS 선택자를 사용하여 첫 번째 일치하는 요소를 선택합니다.
- document.querySelectorAll(selector) : CSS 선택자를 사용하여 일치하는 모든 요소를 선택합니다.
- element.innerText : 요소의 텍스트 콘텐츠를 설정하거나 가져옵니다.
- element.innerHTML : 요소의 HTML 콘텐츠를 설정하거나 가져옵니다.
- element.value : 입력 필드의 값을 설정하거나 가져옵니다.
- element.style.property : 요소의 CSS 스타일 속성을 설정합니다.
- element.click() : 요소를 클릭합니다.
- element.focus() : 요소에 포커스를 설정합니다.
- element.blur() : 요소에서 포커스를 제거합니다.
- window.scrollTo(x, y) : 페이지를 지정된 좌표로 스크롤합니다.
- window.scrollBy(x, y) : 현재 위치에서 지정된 거리만큼 페이지를 스크롤합니다.
- alert(message) : 경고창을 표시합니다.
- confirm(message) : 확인창을 표시하고 사용자의 응답을 반환합니다.
- prompt(message, default) : 입력창을 표시하고 사용자의 입력을 반환합니다.
- form.submit() : 폼을 제출합니다.
- form.reset() : 폼을 초기화합니다.


HTML 안에서 JavaScript를 쓰려면 <script> 탭으로 감싸야함

e.g. <!DOCTYPE html>
     <html>
       <head>
         <title>Input Field Example</title>
       </head>
       <body>
         <h1>Fill the Input Field</h1>
         <input type="text" id="inputField" value="initial value" />
         <button id="submitButton">Submit</button>
    
         <script>
           document.getElementById("submitButton").addEventListener("click", function () {
             alert("Input field value: " + document.getElementById("inputField").value);
           });
         </script>
       </body>
     </html>

** JavaScript 부분 해석: 
    addEventListener : 클릭하면 function 을 실행하라
        ==> function() == alert 를 띄워라
                ==> alert 내용은: Input field value: initial value


.target {} : 태겟 클래스에 대해서 {} 안의 내용대로 설정하라는 뜻









