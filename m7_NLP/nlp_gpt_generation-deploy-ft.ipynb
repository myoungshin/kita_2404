{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/ratsgo/nlpbook/blob/master/examples/sentence_generation/deploy_colab2.ipynb","timestamp":1673055893911}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7ae754a345644f0bb04aa09ecc669d28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d1ca32f984c49bab169167fc06b2ac1","IPY_MODEL_1a134f6723a14896a69be949ccd4df9b","IPY_MODEL_20a207599aff45e2b2688697a88f984b"],"layout":"IPY_MODEL_06559ddc4c714910954c7f92c0e301ed"}},"1d1ca32f984c49bab169167fc06b2ac1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08c1087f5ff6447b9810600a3bd1bd01","placeholder":"​","style":"IPY_MODEL_e6fab43f868e4880994ae3df21a2dd96","value":"config.json: 100%"}},"1a134f6723a14896a69be949ccd4df9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7928e89f1da4e518d2bcc770a2785b0","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c8bc25511b94150ad169b9e5331dfd7","value":1000}},"20a207599aff45e2b2688697a88f984b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8ffb5a35ac44588babbb7f3fc5a3522","placeholder":"​","style":"IPY_MODEL_13328c9a66714a12972342708fe8611d","value":" 1.00k/1.00k [00:00&lt;00:00, 35.3kB/s]"}},"06559ddc4c714910954c7f92c0e301ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08c1087f5ff6447b9810600a3bd1bd01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6fab43f868e4880994ae3df21a2dd96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7928e89f1da4e518d2bcc770a2785b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c8bc25511b94150ad169b9e5331dfd7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8ffb5a35ac44588babbb7f3fc5a3522":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13328c9a66714a12972342708fe8611d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57c9636ba5c74d82857ca45f7deeb69a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_681ad9007785469c8af1872b88f1755f","IPY_MODEL_22ff80a119864eb3ae688e476909fb88","IPY_MODEL_1f7b57f1367c42199283c64095ecd374"],"layout":"IPY_MODEL_1cccc260c19e405dbbed170e41edd76d"}},"681ad9007785469c8af1872b88f1755f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_900eadd2e69b485b94a3ff4af72c503f","placeholder":"​","style":"IPY_MODEL_c1ae7b54b9424202adf1c021cc798bbb","value":"tokenizer.json: 100%"}},"22ff80a119864eb3ae688e476909fb88":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ab248d5c22f4980836b33eec9227135","max":2825034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbc23f053df74422a9794519004d1475","value":2825034}},"1f7b57f1367c42199283c64095ecd374":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5a977c209554dc0847f54142c389fca","placeholder":"​","style":"IPY_MODEL_dd2711c95e8349d481e65c31162ac192","value":" 2.83M/2.83M [00:00&lt;00:00, 11.5MB/s]"}},"1cccc260c19e405dbbed170e41edd76d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"900eadd2e69b485b94a3ff4af72c503f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1ae7b54b9424202adf1c021cc798bbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ab248d5c22f4980836b33eec9227135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbc23f053df74422a9794519004d1475":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5a977c209554dc0847f54142c389fca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd2711c95e8349d481e65c31162ac192":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"8oaGGhdmYKqt"},"source":["# 패키지 설치\n","pip 명령어로 의존성 있는 패키지를 설치합니다.\n"]},{"cell_type":"code","metadata":{"id":"t8TJkXkpDnSq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725409877862,"user_tz":-540,"elapsed":34593,"user":{"displayName":"Myoungshin Lee","userId":"12933823317741169406"}},"outputId":"29d5bd2c-c375-4d54-dde5-18e5b2a87d41"},"source":["# 의존성 패키지 설치하기\n","%pip install pip==24.0.0 -q\n","%pip install ratsnlp -q"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.5/582.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.6.1 has a non-standard dependency specifier torch>=1.8.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjqzgR4BghTU","executionInfo":{"status":"ok","timestamp":1725409902628,"user_tz":-540,"elapsed":22155,"user":{"displayName":"Myoungshin Lee","userId":"12933823317741169406"}},"outputId":"3956aa90-a842-4da2-99b9-a8014f2be4f2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"eC5OwyKMx_l9"},"source":["# 각종 설정\n","모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다.\n"]},{"cell_type":"code","metadata":{"id":"fKybDwDqFIX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725409954292,"user_tz":-540,"elapsed":7316,"user":{"displayName":"Myoungshin Lee","userId":"12933823317741169406"}},"outputId":"29e25249-3bf8-4046-dbb7-143408fff556"},"source":["from ratsnlp.nlpbook.generation import GenerationDeployArguments\n","args = GenerationDeployArguments(\n","    pretrained_model_name=\"skt/kogpt2-base-v2\",\n","    downstream_model_dir=\"/content/drive/MyDrive/KDT_240424/m7_nlp응용/checkpoint-generation1\",\n",")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["downstream_model_checkpoint_fpath: /content/drive/MyDrive/KDT_240424/m7_nlp응용/checkpoint-generation1/epoch=1-val_loss=2.29.ckpt\n"]}]},{"cell_type":"markdown","metadata":{"id":"J3mThtbxyNyO"},"source":["# 모델 로딩\n","파인튜닝을 마친 GPT2 모델과 토크나이저를 읽어 들입니다."]},{"cell_type":"code","metadata":{"id":"aFV031RZFRgD","colab":{"base_uri":"https://localhost:8080/","height":748,"referenced_widgets":["7ae754a345644f0bb04aa09ecc669d28","1d1ca32f984c49bab169167fc06b2ac1","1a134f6723a14896a69be949ccd4df9b","20a207599aff45e2b2688697a88f984b","06559ddc4c714910954c7f92c0e301ed","08c1087f5ff6447b9810600a3bd1bd01","e6fab43f868e4880994ae3df21a2dd96","d7928e89f1da4e518d2bcc770a2785b0","6c8bc25511b94150ad169b9e5331dfd7","a8ffb5a35ac44588babbb7f3fc5a3522","13328c9a66714a12972342708fe8611d"]},"executionInfo":{"status":"ok","timestamp":1725410409236,"user_tz":-540,"elapsed":26828,"user":{"displayName":"Myoungshin Lee","userId":"12933823317741169406"}},"outputId":"6e08e87a-b675-4a17-9f9d-70f6f05801de"},"source":["# 학습시킨 가중치가 적용되도록\n","import torch\n","from transformers import GPT2Config, GPT2LMHeadModel\n","pretrained_model_config = GPT2Config.from_pretrained(\n","    args.pretrained_model_name,\n",")\n","model = GPT2LMHeadModel(pretrained_model_config)\n","fine_tuned_model_ckpt = torch.load(\n","    args.downstream_model_checkpoint_fpath,\n","    map_location=torch.device(\"cpu\"),\n",")\n","model.load_state_dict({k.replace(\"model.\", \"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})\n","model.eval()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ae754a345644f0bb04aa09ecc669d28"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-c3710c30dba0>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  fine_tuned_model_ckpt = torch.load(\n"]},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"C3amlsjpFd9i","colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["57c9636ba5c74d82857ca45f7deeb69a","681ad9007785469c8af1872b88f1755f","22ff80a119864eb3ae688e476909fb88","1f7b57f1367c42199283c64095ecd374","1cccc260c19e405dbbed170e41edd76d","900eadd2e69b485b94a3ff4af72c503f","c1ae7b54b9424202adf1c021cc798bbb","3ab248d5c22f4980836b33eec9227135","fbc23f053df74422a9794519004d1475","f5a977c209554dc0847f54142c389fca","dd2711c95e8349d481e65c31162ac192"]},"executionInfo":{"status":"ok","timestamp":1725410471449,"user_tz":-540,"elapsed":784,"user":{"displayName":"Myoungshin Lee","userId":"12933823317741169406"}},"outputId":"0832804e-d1db-4ff9-9107-8627d1eff9df"},"source":["from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\n","    args.pretrained_model_name,\n","    eos_token=\"</s>\",\n",")"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57c9636ba5c74d82857ca45f7deeb69a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}]},{"cell_type":"markdown","source":["- 탑k 샘플링(top-k sampling)은\n","  - top_k는 확률이 높은 상위 k개의 토큰만을 고려하여 다음 토큰을 선택하는 방법입니다. 즉, 다음 단어의 예측 시 확률이 높은 상위 k개의 토큰 중에서만 선택합니다.\n","  - 예를 들어, top_k=50이라면 확률이 가장 높은 상위 50개의 토큰만을 고려 대상으로 하고, 이 중에서 다음 단어를 무작위로 선택합니다.\n","  - top_k는 모델이 너무 예측 가능한 텍스트를 생성하는 것을 방지하고 다양성을 제공하지만, 때로는 관련 없는 단어를 포함시킬 수 있는 단점이 있습니다.\n","\n","- 탑p 샘플링(top-p sampling)은\n","  - top_p는 누적 확률이 p 이상이 되는 순간까지 가장 확률이 높은 토큰들을 선택하는 방식입니다. 즉, 선택된 토큰들의 누적 확률이 전체 토큰 확률 분포의 p 퍼센트를 차지할 때까지 토큰을 포함합니다. 이 방법을 핵 샘플링(Nucleus Sampling)이라고도 합니다.\n","  - 예를 들어, top_p=0.9라면 확률이 높은 순서대로 토큰을 추가하다가 누적 확률이 90%에 도달하는 순간 멈춥니다. 이렇게 선택된 토큰들 중에서 무작위로 다음 토큰을 선택합니다.\n","  - top_p는 생성된 텍스트의 다양성을 증가시킬 수 있으면서도, 너무 무작위적이지 않게 제어할 수 있는 장점이 있습니다.\n","- 리피티션 패널티(repetition penalty)라는 방식으로 반복을 통제할 수도 있습니다. repetition_penalty라는 인자를 주면 됩니다. 그 값은 1.0 이상이어야 하며 클 수록 페널티가 세게 적용\n","\n","- 템퍼러처 스케일링(temperature scaling)이란\n","  - 모델의 다음 토큰 확률분포에 변형을 가해 문장을 다양하게 생성하는 기법\n","  - 확률분포를 변형한다는 의미는, 대소 관계의 역전 없이 분포의 모양만을 바꾼다는 의미\n","  - 이 값이 0에 가까울 수록 확률분포 모양이 원래 대비 뾰족해 진다. 순위의 변동은 없지만 원래 컸던 확률은 더 커지고, 작았던 확률은 더 작아져 확률분포의 모양이 뾰족(sharp)해진다. 그만큼 확률값 기준 1등 토큰이 다음 토큰으로 뽑힐 가능성이 높아진다. temperature의 기술적 범위는 0을 제외한 양수 전체\n","  - temperature를 1보다 작게 하면 상대적으로 정확한 문장을, 1보다 크게 하면 상대적으로 다양한 문장을 생성한다.A higher temperature will result in more random predictions, while a lower temperature will result in more confident predictions.\n","\n","- no_repeat_ngram_size 매개변수는\n","  - 언어 모델이 텍스트를 생성할 때 특정 크기의 n-gram이 반복되지 않도록 하는 기능을 설정합니다. n-gram은 인접한 n개의 아이템(이 경우 단어)으로 구성된 시퀀스입니다. 이 매개변수는 생성된 텍스트 내에서의 반복을 줄이고, 다양성과 창의성을 높이는 데 도움을 줄 수 있습니다.\n","  - no_repeat_ngram_size가 0이면: 이 기능이 비활성화됩니다. 즉, 모델이 텍스트를 생성할 때 어떤 크기의 n-gram도 반복될 수 있습니다.\n","  - no_repeat_ngram_size가 2 이상의 정수로 설정된 경우: 지정된 크기의 n-gram이 생성된 텍스트 내에서 한 번만 나타나도록 합니다. 예를 들어, no_repeat_ngram_size를 2로 설정하면 어떤 두 단어의 조합도 텍스트 내에서 단 한 번만 나타날 수 있습니다. 이는 특히 장기적인 텍스트 생성에서 반복되는 패턴이나 구문의 반복을 방지하는 데 유용합니다.\n"],"metadata":{"id":"WjOzgbQRpqJc"}},{"cell_type":"markdown","metadata":{"id":"ZWVsdmThyV_p"},"source":["# 인퍼런스 함수 선언\n","인퍼런스 함수를 선언합니다."]},{"cell_type":"code","metadata":{"id":"fnzR9NMtFiAz","executionInfo":{"status":"ok","timestamp":1725410680752,"user_tz":-540,"elapsed":412,"user":{"displayName":"Myoungshin Lee","userId":"12933823317741169406"}}},"source":["def inference_fn(\n","        prompt,\n","        min_length=10,\n","        max_length=20,\n","        top_p=1.0, # 확률적으로 선택되는 후보군의 누적 확률의 임계값. top_p가 1.0인 경우, 모든 후보가 선택\n","        top_k=50, # 각 단계에서 고려할 확률이 높은 상위 k개의 토큰\n","        repetition_penalty=1.0, # 반복되는 단어에 대한 패널티를 조정합니다. 1.0보다 크면 반복을 억제\n","        no_repeat_ngram_size=0, # 생성된 텍스트 내에서 반복되지 않아야 하는 n-gram의 크기\n","        temperature=1.0, # 생성 다양성을 조절. 값이 낮을수록 예측이 보수적\n","):\n","    try:\n","        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n","        with torch.no_grad():\n","            generated_ids = model.generate(\n","                input_ids,\n","                do_sample=True, # 토큰 생성 시 샘플링을 통해 다양성을 높입니다.\n","                top_p=float(top_p), # 생성 과정에서 이 임계값을 넘는 토큰만을 고려\n","                top_k=int(top_k), # 각 단계에서 고려할 상위 k개의 토큰\n","                min_length=int(min_length),\n","                max_length=int(max_length),\n","                repetition_penalty=float(repetition_penalty), # 반복되는 토큰에 대한 패널티를 적용\n","                no_repeat_ngram_size=int(no_repeat_ngram_size),\n","                temperature=float(temperature), # 값이 낮을수록 예측이 더 확정적이 됩니다.\n","           )\n","        generated_sentence = tokenizer.decode([el.item() for el in generated_ids[0]])\n","    except:\n","        generated_sentence = \"\"\"처리 중 오류가 발생했습니다. <br>\n","            변수의 입력 범위를 확인하세요. <br><br>\n","            min_length: 1 이상의 정수 <br>\n","            max_length: 1 이상의 정수 <br>\n","            top-p: 0 이상 1 이하의 실수 <br>\n","            top-k: 1 이상의 정수 <br>\n","            repetition_penalty: 1 이상의 실수 <br>\n","            no_repeat_ngram_size: 1 이상의 정수 <br>\n","            temperature: 0 이상의 실수\n","            \"\"\"\n","    return {\n","        'result': generated_sentence,\n","    }"],"execution_count":6,"outputs":[]},{"cell_type":"code","source":["inference_fn(\n","        prompt='안녕하세요',\n","        min_length=10,\n","        max_length=50,\n","        top_p=0.9,\n","        top_k=50,\n","        repetition_penalty=1.1,\n","        no_repeat_ngram_size=3,\n","        temperature=1.0,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fkneH1F2yWsH","executionInfo":{"status":"ok","timestamp":1725410710138,"user_tz":-540,"elapsed":784,"user":{"displayName":"Myoungshin Lee","userId":"12933823317741169406"}},"outputId":"abf2e521-426e-494f-9801-c30914c9d5c3"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'result': '안녕하세요!!! 꼭보세요ᄒᄒᄒ</s>'}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["inference_fn(\n","        prompt='안녕하세요',\n","        min_length=10,\n","        max_length=50,\n","        top_p=0.5,\n","        top_k=10,\n","        repetition_penalty=1.0,\n","        no_repeat_ngram_size=2,\n","        temperature=0.1,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRRGa--yePKC","executionInfo":{"status":"ok","timestamp":1725410715467,"user_tz":-540,"elapsed":808,"user":{"displayName":"Myoungshin Lee","userId":"12933823317741169406"}},"outputId":"1de16bfe-b05f-4954-c473-3c9e8899926e"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'result': '안녕하세요..이거보고나서..정말재밌었어요</s>'}"]},"metadata":{},"execution_count":10}]}]}